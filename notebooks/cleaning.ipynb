{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove:\n",
    "* Null values, new_line(\"\\n\"), hashtags(\"#*\"), emojis, other characters\n",
    "### Replace:\n",
    "* ['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'] with ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']\n",
    "* ['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'] with ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']\n",
    "* ['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'] with ['ሰ, 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']\n",
    "* ['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'] with ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']\n",
    "* ['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'] with ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join('../src/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [\n",
    "  [['ሐ', 'ሑ', 'ሒ', 'ሓ', 'ሔ', 'ሖ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],\n",
    "  [['ኀ', 'ኁ', 'ኂ', 'ኃ', 'ኄ', 'ኅ', 'ኆ'], ['ሀ', 'ሁ', 'ሂ', 'ሃ', 'ሄ', 'ህ', 'ሆ']],\n",
    "  [['ሠ', 'ሡ', 'ሢ', 'ሣ', 'ሤ', 'ሦ', 'ሦ', 'ሧ'], ['ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ']],\n",
    "  [['ዐ', 'ዑ', 'ዒ', 'ዓ', 'ዔ', 'ዕ', 'ዖ'], ['አ', 'ኡ', 'ኢ', 'ኣ', 'ኤ', 'እ', 'ኦ']],\n",
    "  [['ጸ', 'ጹ', 'ጺ', 'ጻ', 'ጼ', 'ጽ', 'ጾ'], ['ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ']]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set directories for parsed data and cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dir = \"../data/parsed\"\n",
    "cleaned_dir = \"../data/cleaned\"\n",
    "util = utils.Util()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parsed_data(folder_path):\n",
    "    # Check if the provided path is a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"{folder_path} is not a valid directory.\")\n",
    "        return\n",
    "    \n",
    "    # check if cleaned_dir exists\n",
    "    if not os.path.exists(cleaned_dir):\n",
    "            os.makedirs(cleaned_dir)\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        base_name, extension = os.path.splitext(file_name)\n",
    "        print(base_name,extension)\n",
    "        if extension =='.csv':\n",
    "            df = pd.read_csv(f\"{folder_path}/{file_name}\", index_col='id')\n",
    "            df = df.dropna()\n",
    "            df = df.replace('\\n', ' ', regex=True)\n",
    "            # Extract and remove hashtags\n",
    "            df['hashtags'] = df['text'].apply(lambda x: util.extract_hashtags(x))\n",
    "            df['text'] = df['text'].str.replace(r'\\#\\w+', '', regex=True)\n",
    "            \n",
    "            # Extract and remove emojis using regex\n",
    "            df['emojis'] = df['text'].apply(util.extract_emojis)\n",
    "            df['text'] = df['text'].apply(util.remove_emojis)\n",
    "\n",
    "            for letter in letters:\n",
    "                for i in range(len(letter[0])):\n",
    "                    df['text'] = df['text'].str.replace(letter[0][i], letter[1][i])\n",
    "            # extract and Reove symbols\n",
    "            df['symbols'] = df['text'].apply(util.extract_symbols)\n",
    "            df['text'] = df['text'].apply(util.remove_symbols)\n",
    "            # extract and remove urls\n",
    "            df['links'] = df['text'].apply(util.extract_urls)\n",
    "\n",
    "            df['text'] = df['text'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "            df['text'] = df['text'].replace(r'!+', '!', regex=True)\n",
    "            df['text'] = df['text'].replace(r'\\.+', '', regex=True)\n",
    "            base_name, extension = os.path.splitext(file_name)\n",
    "            df.to_csv(f\"{cleaned_dir}/{base_name}.csv\")\n",
    "            df['text'].to_csv(f\"{cleaned_dir}/{base_name}.txt\", index=False, header=False)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ዳጉ ስፖርት DAGU SPORT .csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ብስራት ስፖርት .csv\n",
      "DID U KNOW️⁉️ .csv\n",
      "🔶Wonder🤔 .csv\n",
      "ETHIO-MEREJA® .csv\n",
      "Sheger Press️️ .csv\n",
      "QUBEE ACADEMY .csv\n",
      "90 ደቂቃ ስፖርት™ .csv\n",
      "4-3-3 FAST SPORT™ .csv\n",
      "THE GOAT LM♾ 🐐 .csv\n",
      "TIKVAH .csv\n",
      "Wasu Mohammed(ዋሱ መሀመድ) .csv\n",
      "ETHIO ARSENAL .csv\n",
      "ኢትዮ መረጃ - NEWS .csv\n",
      "😍Best Profile Pictures😍 .csv\n",
      "History 📚 .csv\n",
      "DREAM APP™ .csv\n",
      "አስደናቂ እውነታዎች 🌍 .csv\n",
      "አዲስ ነገር መረጃ .csv\n",
      "ኢትዮ ሪያል ማድሪድ .csv\n",
      "DREAM SPORT ™ .csv\n",
      "Ethio University News® .csv\n",
      "💕🎄ፍቅርን በቃላት🎄💕 .csv\n",
      "YeneTube .csv\n",
      "Manchester United Fans™ .csv\n"
     ]
    }
   ],
   "source": [
    "clean_parsed_data(parsed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
